---
title  : El objeto que no lo era
slug   : el-objeto-que-no-lo-era
author : Javier Vélez
date   : Jun 2022
draft  : true
hidden : false
---

Seguro que a ti te pasa lo mismo que a mí. Los desarrolladores hemos sido formados para concebir la algoritmia de una manera imperativa. Un programa es una secuencia de pasos que se ejecutan de forma ordenada para transformar un estado ambiental soportado por parámetros y variables. La mayoría de paradigmas y lenguajes más populares hasta la fecha se han basado en este modelo de ejecución. Hasta tal punto es acuciado nuestro condicionamento que frecuentemente nos cuesta mucho pensar que existen otras formas de pensar [+].

La programación funcional - tal vez por su fuerte enraizamiento histórico al mundo de las matemáticas - es un ejemplo de paradigma no imperativo. Dicho mal y pronto en programación funcional todo son expresiones funcionales compuestas entre sí para generar un resultado final.

Esta diferencia parece fácil de asimilar si nos quedamos en la superficie. Pero lo cierto es que en todo esto se encierran implicaciones mucho más relevantes. La programación basada en control de flujo típica del modelo de ejecución imperativo - el uso de sentencias iterativas o condicionales - queda invalidada en este paradigma. En efecto, todas estas sentencias se apoyan en el uso de un estado ambiental soportado por variables y la programación funcional no utiliza ese modelo. De hecho, el propio término de sentencia en programación funcional es un contrasentido en si mismo.

Entonces, ¿cómo se consigue alcanzar un nivel competitivo de operatividad? En general esto se logra por aplicación de combinadores funcionales [+]. Dicho de manera más específica, la ejecución de funciones en secuencia se articula por medio de la composición funcional, la ejecución condicional por medio del uso de operadores de casos y la iterativa por medio de la recursión. Ya hemos llegado donde queríamos.

Por mover estas ideas al código comparemos cómo sería un algoritmo que permita resolver el cálculo del factorial [1] de un número por aplicación de un esquema de diseño iterativo y recursivo. El siguiente listado muestra una versión imperativa del problema. Como puede apreciarse, la ejecución se apoya en un estado ambiental formado por dos variables locales (r e i) y un parámetro (n) que se va transformando a lo largo del tiempo.

odo lo anterior resulta perfectamente válido en el plano teórico. El diseño recursivo es potente, eficaz y en no pocas ocasiones genera código más sencillo de entender. Punto aparte es cómo un ordenador con arquitectura de Von Newmann [3] puede dar soporte a la ejecución de este tipo de algoritmos.

Hoy en día cabría pensar que los lenguajes de programación siempre dieron soporte a la ejecución recursiva pero lo cierto es que hasta finales de los 70 no se popularizaron los compiladores con esta capacidad. Los detalles de tal complejidad residen en cómo el compilador o interprete debe llevar a cabo la gestión de la memoria.

Si retomamos el ejemplo del listado 1, dado su carácter no recursivo podemos asegurar que nunca existirán 2 invocaciones de la función factA solapantes en el tiempo. Es decir, antes de que una nueva invocación de factA se produzca se debe haber terminado con cualquier otra invocación anterior. Con esto no estamos haciendo otra cosa que destacar una propiedad del modelo de ejecución no recursivo.

Sin embargo, en el esquema recursivo del listado 2, las invocaciones de la función factB sí que son solapantes en el tiempo dado que cada llamada a la función que entre por el caso recursivo provoca una nueva invocación de la función fracB cuyo tiempo de vida comienza y acaba antes de que termine la invocación en curso.

Veamos ahora cómo este hecho afecta a la gestión de memoria que debe hacerse. En los dos listados anteriores se manejan elementos de datos tal y como comentamos anteriormente. Sin embargo, existen importantes diferencias. En la ejecución imperativa de factA puede establecerse una correspondencia 1:1 entre dichos elementos a nivel simbólico - las variables y parámetros n, r e i - y las posiciones de memoria física donde se almacenan dichos datos. En la versión recursiva de factB, por el contrario, cada uno de los elementos simbólicos del algoritmo - en este caso tan sólo el parámetro n - debe alojarse en una dirección física de memoria diferente estableciéndose así una correspondencia 1:N entre referencias simbólicas y datos en memoria.

Es decir, mientras que en la versión imperativa de factA cada variable o parámetro refiere siempre al mismo espacio de datos en memoria, en el esquema recursivo de factB el parámetro n hace referencia de forma simultánea a todos los valores que alcance n a lo largo del tiempo. Por ejemplo, al hacer la invocación factB(5) deberíamos ser conscientes como desarrolladores de que, en este caso, en parámetro n es una referencia simbólica - más o menos simultánea a nivel sintáctico - de los datos 5, 4, 3, 2, 1, 0.

La razón resulta evidente si lo relacionamos con los modelos de activación. En las invocaciones de factA cada referencia física a los datos puede reutilizarse de invocación en invocación dado que no existe solapamiento temporal entre las mismas. Por el contrario, en el caso del diseño recursivo de la función factB cada valor de n debe respetarse hasta que termine su ejecución. Ello exige que las invocaciones solapantes requieran alojar los nuevos valor de n en cada invocación en un espacio nuevo de memoria.

En resumen, ello implica que para las funciones no recursivas puede hacerse un direccionamiento absoluto a memoria de los elementos de datos implicados mientras que en los esquemas recursivos se exigen direccionamientos relativos a memoria cuya organización más conveniente es en forma de pila. Dado su carácter más general, los compiladores actuales hacen una gestión de memoria en forma de pila para la ejecución de cualquier función, con independencia de su diseño recursivo o no recursivo. Aquí surge la famosa pila que tantas veces se nos ha desbordado cuando hacemos por error un diseño recursivo que no garantiza la convergencia hacia algún caso base desde cualquier caso recursivo y, si lo hace, esto se produce en tiempo posterior al llenado de la pila.

Optimización por Recursión en la Cola
En términos de rendimiento en memoria debería quedar clara una cosa. Los esquemas recursivos puede que sean más claros, eficaces y sencillos de entender en muchas ocasiones pero desde luego suponen - al menos desde una perspectiva estructural - una gran cantidad de consumición de recursos de memoria en comparación con sus equivalentes no recursivos. La valoración de este hecho es algo que debe hacerse con sentido común - algo poco frecuente en general al hablar de optimización y rendimiento [+]. - dado que siempre hay que relativizar la consumición de recursos en relación a su proporción disponible.

No obstante, cabría preguntarse si siempre siempre debe mantenerse esta correspondencia 1:N entre referencias de datos y direcciones físicas de memoria que parece ser la madre de todos los males. Si retomamos la función observamos que en realidad la única necesidad de mantener en memoria el valor del parámetro n después de hacer una nueva invocación a factB es por la necesidad de hacer una operación de combinación ulterior para producir el resultado retornado. Me estoy refiriendo, en este ejemplo a la operación de producto por n. A las funciones recursivas que requieren de este tipo de operación posterior a la llamada se las clasifica como funciones de recursividad no final, mientras que aquellas cuyos casos recursivos acaban directamente con una llamada recursiva se consideran funciones de recursividad final.

Cabe reflexionar entonces que si la función factB tuviera un esquema de recursividad final, el compilador podría detectar este hecho y evitar tener que montar un modelo de gestión de memoria basado en pila dado que los datos, aun en correspondencia mantenida 1:N no se van a utilizar con posterioridad a cada nueva llamada recursiva. Eso es lo que se conoce como optimización por recursión en la cola.

La única pregunta que queda es si es posible transformar el diseño recursivo de la función factB en otro diseño factC equivalente pero con un esquema de recursividad final. Como se muestra en el listado 3, puede encontrarse dicha transformación por aplicación de técnicas de inversión funcional [+].