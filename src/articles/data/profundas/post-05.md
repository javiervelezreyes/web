---
title  : Redes Neuronales Convolucionales
slug   : redes-neuronales-convolucionales
author : Javier Vélez
date   : Mayo 2024
---

## Introducción

La Inteligencia Artificial Conexionista parecía estar ganando impulso en su desarrollo. Desde los modelos iniciales de la neurona artificial propuestos por McCulloch y Pitts allá por el año 1943, hasta la reinterpretación de Rosenblatt 15 años después, que la concibió como un clasificador geométrico, se fueron sentando las bases de lo que hoy conocemos como redes neuronales. Años más tarde, en 1969, el modelo de clasificador multicapa de Minsky y Papert, junto con las redes de base radial de Park y Sandberg en 1981, demostrarían la capacidad de resolver problemas de clasificación no lineal, abriendo un abanico de posibilidades en el campo del reconocimiento de patrones.

Por su parte, los modelos topológicos de Kohonen publicados en 1982 habrían mostrado la posibilidad de aplicar técnicas de aprendizaje no supervisado para identificar patrones de agrupamiento en los datos, lo que supuso un avance significativo en la capacidad de las máquinas para descubrir conocimiento de forma autónoma. Este hecho despertaría un gran interés por seguir explorando técnicas de descubrimiento, donde las redes neuronales pudieran extraer información valiosa sin necesidad de una supervisión constante. 

El desafío principal radicaba en diseñar arquitecturas de red que pudieran ir más allá de la simple clasificación o predicción, y que fueran capaces de encontrar relaciones y estructuras ocultas en los datos sin la necesidad de etiquetas predefinidas. Esto abriría la puerta a la resolución de problemas más complejos, como la segmentación de imágenes, el análisis de datos no estructurados y la identificación de anomalías, donde la capacidad de la red para aprender representaciones significativas de los datos se conviertiría en un factor crucial.

Es precisamente en este caldo de cultivo donde emergerían las redes neuronales convolucionales que representarían un nuevo tipo de arquitectura como solución potente en esta línea. La capacidad de estas redes para procesar datos con una estructura espacial inherente, como imágenes o señales de audio, y extraer automáticamente características relevantes, supondría un salto cualitativo en el desarrollo de sistemas de Inteligencia Artificial. A diferencia de otros tipos de arquitecturas de red más convencionales, que a menudo requerían un preprocesamiento manual y laborioso de los datos para identificar los rasgos distintivos, las nuevas redes convolucionales serían capaces de aprender estos rasgos de manera autónoma a través de capas especializadas que aplicarían operaciones de convolución sobre los datos. A lo largo de este artículo abordaremos su descripción, funcionamiento operativo y pragmática de uso.

## Redes Neuronales Convolucionales

A principios de los años 80, el interés por desarrollar modelos de red neuronal capaces de extraer patrones directamente de los datos estaba experimentando un crecimiento significativo. Los modelos de aprendizaje supervisado, que habían demostrado su eficacia en la resolución de problemas de clasificación y predicción, estaban cediendo terreno a la investigación en problemas de clusterización y asociación, donde el objetivo era descubrir estructuras ocultas en los datos sin necesidad de etiquetas predefinidas. Las arquitecturas de red topológicas de Kohonen, introducidas en 1982, ya habían marcado un hito en esta dirección, al permitir la autoorganización de los datos en mapas topológicos que reflejaban sus relaciones intrínsecas.

Este contexto fue el caldo de cultivo para la concepción de un nuevo tipo de redes neuronales alla por el año 1985 de la mano de LeCun. Se trataba de soluciones que incorporaban operaciones de convolución, una técnica matemática que permite extraer características locales de los datos. La idea esencial detrás de las redes convolucionales era diseñar una arquitectura que pudiera aprender a identificar patrones espaciales jerárquicos, es decir, patrones de baja complejidad que, combinados, forman patrones de mayor complejidad. 

En este tipo de redes, se introducirían capas especializadas que realizan operaciones de convolución, lo que les permite extraer características espaciales de los datos de entrada, como bordes, texturas y formas. En particular, sobre este tipo de arquitecturas, es posible reconocer diferentes tipos de capas donde se disponen las neuronas. A continuación, describimos en detalle cada una de ellas.

- **Capas Convolucionales.** Estas capas constituyen el núcleo de la red, siendo las responsables de llevar a cabo la operación de convolución. Dicha operación implica el deslizamiento de un filtro, representado por una pequeña matriz de pesos, sobre la entrada de datos. En cada posición, se calcula el producto punto entre los valores del filtro y la región correspondiente de la entrada que este cubre. Este proceso permite a la red extraer características locales relevantes de los datos, tales como bordes, texturas o patrones específicos.
    
- **Capas de Pooling.** Estas capas tienen como objetivo reducir la dimensionalidad de las representaciones aprendidas por las capas convolucionales. Al disminuir el número de parámetros, se optimiza la eficiencia computacional de la red y se incrementa su robustez frente a pequeñas variaciones o desplazamientos en los datos de entrada. Existen diferentes técnicas de pooling, como el max pooling o el average pooling, cada una con sus propias características y efectos sobre la información procesada.
    
- **Capas de Activación.** La introducción de no linealidades en la red neuronal es crucial para permitirle aprender funciones complejas y modelar relaciones no lineales entre los datos. Las capas de activación cumplen esta función al aplicar una función no lineal a la salida de las capas anteriores. En este punto se aplican las funciones de activación convencionalmente utilizadas en arquitecturas neuronales, cada una con sus propias ventajas y desventajas en términos de eficiencia y capacidad de aprendizaje.
    
- **Capas Totalmente Conectadas.** Estas capas, también conocidas como capas densas, suelen ubicarse al final de la red y se encargan de realizar la clasificación final o la predicción. En estas capas, cada neurona está conectada a todas las neuronas de la capa anterior, lo que permite combinar las características extraídas por las capas convolucionales y de pooling para tomar una decisión global sobre la entrada.
    
Para comprender mejor las operaciones de convolución, imaginemos que tenemos una imagen en blanco y negro representada como una matriz de píxeles, donde cada valor representa la intensidad del píxel. Aplicar una operación de convolución con un filtro específico equivale a deslizar ese filtro sobre la imagen, multiplicando los valores del filtro por los valores de los píxeles que cubre, y sumando los resultados para obtener un único valor de salida. Este proceso se repite para cada posición del filtro sobre la imagen, generando una nueva matriz que representa la respuesta de la convolución. Al utilizar diferentes filtros, la red puede aprender a extraer diferentes tipos de características de la imagen, como bordes horizontales, verticales o diagonales.

Este modelo de operación tenía sentido porque permitía a la red aprender representaciones jerárquicas de los datos, donde las capas iniciales extraen características de bajo nivel y las capas posteriores combinan estas características para formar representaciones de alto nivel. Esta capacidad de aprender características de forma automática es una de las principales ventajas de las redes convolucionales, ya que evita la necesidad de diseñar manualmente extractores de características, una tarea que puede ser muy laboriosa y requerir un conocimiento profundo del dominio del problema.

Entre las ventajas de las redes convolucionales se encuentra su capacidad para manejar datos con estructura espacial, como imágenes y señales de audio, de manera eficiente. Además, su arquitectura permite reducir el número de parámetros en comparación con las redes totalmente conectadas, lo que facilita su entrenamiento y reduce el riesgo de sobreajuste. Sin embargo, las redes convolucionales también presentan algunos inconvenientes, como la necesidad de una gran cantidad de datos para su entrenamiento y la dificultad para interpretar las representaciones aprendidas por las capas internas.

## Redes Neuronales Convolucionales en Acción

Las ideas que fundamentan las redes neuronales convolucionales tienen sus raíces en la biología, específicamente en los descubrimientos sobre el funcionamiento de ciertas neuronas de la corteza visual en los procesos de visión. Décadas atrás, los neurocientíficos ya habían descubierto que algunas neuronas de la corteza visual responden selectivamente a características visuales específicas, como bordes, orientaciones y movimientos. Este hallazgo sugirió que el sistema visual humano procesa la información de forma jerárquica, extrayendo características simples en las etapas iniciales y combinándolas para formar representaciones más complejas en las etapas posteriores.

Este hecho vinculó rápidamente el uso práctico de las redes convolucionales a escenarios de visión artificial, donde el objetivo principal es permitir a las máquinas ver e interpretar el mundo visual de la misma manera que lo hacen los humanos. En estos escenarios, se busca que las máquinas puedan realizar tareas como la clasificación de imágenes (identificar el contenido de una imagen), la detección de objetos (localizar objetos específicos dentro de una imagen) y el reconocimiento facial (identificar personas a partir de sus rostros). Las características de este tipo de problemas están marcadas por varios aspectos clave. 

- **Estructura Espacial de los Datos.** En primer lugar, los datos de entrada en problemas de visión artificial y tareas relacionadas suelen tener una estructura espacial inherente. Esto es particularmente evidente en las imágenes, donde los píxeles están organizados de manera regular en una cuadrícula bidimensional. La posición de cada píxel y su relación con los píxeles vecinos contienen información crucial sobre el contenido de la imagen. Por ejemplo, los bordes de un objeto se definen por cambios abruptos en la intensidad de los píxeles adyacentes, y las texturas están formadas por patrones repetitivos de píxeles. Ignorar esta estructura espacial implicaría perder información valiosa y limitar la capacidad del modelo para comprender la escena visual. Las redes convolucionales están diseñadas específicamente para explotar esta estructura espacial mediante la aplicación de operaciones de convolución que preservan las relaciones entre los píxeles cercanos.
    
- **Variabilidad de los Objetos.** En segundo lugar, los objetos presentes en las imágenes pueden exhibir una gran variabilidad en términos de su posición, escala, orientación, deformación y oclusión. Un mismo objeto puede aparecer en diferentes partes de la imagen, puede ser más grande o más pequeño, puede estar rotado en diferentes ángulos, puede sufrir deformaciones no rígidas, o puede estar parcialmente oculto por otros objetos. Esta variabilidad representa un desafío importante para los modelos de visión artificial, ya que deben ser capaces de reconocer los objetos independientemente de estas transformaciones. Las redes convolucionales abordan este problema mediante el uso de capas de pooling, que proporcionan cierta invariancia a pequeñas traslaciones y distorsiones, y mediante el aprendizaje de representaciones robustas que capturan las características esenciales de los objetos más allá de su apariencia específica.
    
- **Volumen de Datos.** En tercer lugar, la cantidad de datos disponibles para entrenar los modelos de visión artificial suele ser muy grande. Las imágenes y los videos son omnipresentes en el mundo digital, y los conjuntos de datos utilizados para entrenar redes neuronales pueden contener millones o incluso miles de millones de ejemplos. Este gran volumen de datos plantea desafíos computacionales significativos en términos de almacenamiento, procesamiento y tiempo de entrenamiento. Se requieren arquitecturas de red eficientes y técnicas de entrenamiento optimizadas para manejar estos conjuntos de datos masivos. Las redes convolucionales, con su arquitectura de pesos compartidos y capas de pooling, son relativamente eficientes en comparación con las redes totalmente conectadas, pero aun así, el entrenamiento de modelos de visión artificial a gran escala requiere una infraestructura computacional potente y distribuida."

Podemos citar algunos problemas típicos que se pueden resolver eficazmente con soluciones convolucionales. Entre elloss se incluye la clasificación de imágenes médicas para detectar enfermedades, la conducción autónoma de vehículos, donde las redes convolucionales procesan las imágenes de las cámaras para identificar objetos y señales de tráfico, o el reconocimiento de gestos para la interacción humano-computadora. En todos estos casos, las redes convolucionales demuestran su capacidad para extraer características relevantes de los datos visuales y tomar decisiones precisas.

Las operaciones de convolución resultan óptimas para este tipo de casos debido a su capacidad para explotar la estructura espacial de los datos, su robustez ante las variaciones en la entrada y su eficiencia computacional. Al aplicar filtros convolucionales, la red puede aprender a identificar patrones locales en la imagen, como bordes, texturas y formas, independientemente de su posición exacta. Las capas de pooling, por su parte, reducen la dimensionalidad de las representaciones aprendidas, lo que permite a la red enfocarse en las características más importantes y disminuir la cantidad de cálculos necesarios.

## Conclusiones

A lo largo de este último artículo de la serie, hemos explorado en detalle las redes neuronales convolucionales, una arquitectura fundamental en el campo de la Inteligencia Artificial. Este tipo de arquitecturas se han presentado como una solución muy potente debido a su capacidad para extraer características relevantes de los datos de forma automática, lo que las hace especialmente adecuadas para problemas con estructura espacial, como la visión artificial.

A las contribuciones establecidas hasta la fecha en el campo de las redes neuronales, se sumaba ahora la habilidad de aplicar técnicas de convolución, lo que permitía a los modelos aprender representaciones jerárquicas de los datos. Esta idea permitía que las redes convolucionales pudieran identificar patrones de baja complejidad en las capas iniciales y combinarlos para formar representaciones de alto nivel en las capas posteriores, lo que les confiere una gran capacidad de abstracción.

A día de hoy, este tipo de redes están en el centro de cualquier problema de visión artificial, desde la clasificación de imágenes hasta la detección de objetos y el reconocimiento facial. Su eficacia y versatilidad las han convertido en una herramienta indispensable para resolver desafíos complejos en diversos campos, como la medicina, la conducción autónoma y la seguridad.

Las redes neuronales convolucionales constituyen un cierre perfecto a las arquitecturas complejas que hemos descrito a lo largo de esta serie. Lo que se hizo patente a lo largo de esta evolución es que la potencia de cómputo en arquitecturas conexionistas no venía de la mano de crear modelos de solución más complejos, sino arquitecturas de red distribuidas donde un mayor número de neuronas operando localmente como clasificadores lineales simples serían capaces de arrojar una respuesta compositiva de gran potencia.

El relato teórico ya no estaría tanto en el comportamiento interno de una neurona artificial operando como unidad de procesamiento, sino en cómo podían idearse diferentes arquitecturas de red que, aplicando diferentes modelos de operación y aprendizaje, pudieran resolver nuevas familias de problemas. El camino para una Inteligencia Artificial potente e imitativa había quedado sembrado para empezar a generar valor real algunos años después. Ahora solo era necesario disponer de datos de calidad para nutrir estas soluciones.