---
title  : Modelos de Aprendizaje
slug   : modelos-de-aprendizaje
author : Javier Vélez
date   : Abril 2024
---

## Introducción

Como ya comentamos en articulos anteriores de esta serie, los inicios de la Inteligencia Artificial Conexionista se remontan a los trabajos originales de Mc Cullock y Pitts, quienes concibieron un modelo formal de la neurona artificial. Este modelo, aunque abstracto, sentó las bases conceptuales para comprender el procesamiento de información a través de unidades interconectadas, emulando de alguna manera la estructura del cerebro biológico. Su propuesta inicial abrió un camino inexplorado que posteriormente otros investigadores se encargarían de desarrollar y refinar.

Un avance significativo, en este sentido, es la interpretación práctica que hizo Frank Rosenblatt del modelo de neurona poniendola en perspectiva como una unidad de procesamiento de grandes volumenes de datos. Rosenblatt reformuló la neurona como un clasificador capaz de separar los datos en diferentes categorías mediante la definición de hiperplanos en un espacio multidimensional. Esta visión aportó una comprensión más intuitiva y aplicable de cómo una neurona podría discriminar entre distintas entradas.

Pero la visión de Rosenblatt fue más allá de la simple reinterpretación geométrica al enfatizar la conveniencia de modular el conjunto de pesos sinápticos para ajustarlos a las necesidades del problema. La adaptabilidad de estos pesos, introdujo así un mecanismo fundamental para el aprendizaje automático que se convertiría en la piedra angular de los modelos de aprendizaje en redes neuronales.

Con esta innovadora perspectiva, Rosenblatt había establecido la fase de aprendizaje sobre datos de entrenamiento como un paso preliminar esencial en la Inteligencia Artificial Conexionista. Antes de que una red neuronal pudiera entrar en producción de manera efectiva, debía ser expuesta a un gran volumen de datos que le permitiera ajustar sus pesos sinápticos de forma apropiada y automática. El comportamiento inteligente sería así una consecuencia natural mimética del aprendizaje previamente adquirido desde los datos de entrenamiento. 

De esta manera, emergiría con el tiempo la concepción de arquitecturas de redes neuronales inherentemente generalistas. Lejos de ser sistemas programados para tareas específicas, estas redes poseerían una estructura flexible cuya respuesta se adaptaría y moldearía a través de procesos formales de aprendizaje. La clave residía en la capacidad de las redes para extraer patrones y relaciones complejas directamente de los datos, ajustando sus parámetros internos para reflejar esas regularidades.

A lo largo de este artículo, nos adentraremos en la exploración de los principales modelos de aprendizaje que han surgido a partir de estas ideas iniciales. Analizaremos las diferentes estrategias y modelos de aprendizaje que permiten a las redes neuronales hoy en día adquirir conocimiento y desarrollar la capacidad de resolver una amplia gama de problemas en el campo de la Inteligencia Artificial Conexionista.

## Modelos de Aprendizaje

El factor de diferenciación que marcó la Inteligencia Artificial Conexionista frente a otras aproximaciones radicaba en su capacidad intrínseca para adquirir conocimiento de forma autónoma. Esta adquisición se fundamentaba en procesos de aprendizaje dirigidos y guiados por la exposición a grandes volúmenes de datos de entrenamiento relevantes para la tarea en cuestión.

La estrategia conexionista contrastaba de manera significativa con la Inteligencia Heurística predominante en aquél entonces. Los sistemas de Inteligencia Artificial más convencionales de la época se basaban principalmente en procedimientos algorítmicos dirigidos por criterios de mejor opción aproximada. En cambio, esta nueva aproximación, ofrecía la promesa de que los sistemas pudieran aprender directamente de la experiencia, sin la necesidad de una programación explícita para cada escenario posible.

De manera similar, el conexionismo presentaría fuertes diferencias con la Inteligencia Artificial Simbólica que se desarrollaría con notable interés aunque poco éxito consolidado durante la década siguiente. La Inteligencia Simbólica se centraría, en este sentido, en la manipulación de símbolos abstractos y estructuras de códificación para representar el conocimiento y realizar razonamientos potencialente complejos. Sin embargo, frente a esa idea, la aproximación conexionista se basaba en la computación distribuida y paralela de unidades simples interconectadas - llamadas neuronas - aprendiendo patrones a través de la modificación de sus conexiones sinápticas.

El desarrollo de este perímetro de la Inteligencia Artificial, aunque con sus idas y venidas, ha crecido mucho y hoy en dia es reconocido indiscutiblemente como una de las áreas de investigación y desarrollo de comportamientos emergentes más próspera y productiva. En este sentido, dentro del vasto panorama de la Inteligencia Artificial Conexionista, es posible reconocer actualmente varios modelos de aprendizaje fundamentales que han demostrado su eficacia en diversas aplicaciones a través de los años. A continuación los describimos someramente.

- **Aprendizaje Supervisado.** En este modelo el sistema aprende a partir de un conjunto de entrenamiento donde cada dato  está además etiquetado con la respuesta correcta deseada. El objetivo es que la neurona aprenda a asociar las entradas a las salidas correctas, de manera que pueda generalizar a nuevos datos no conocidos durante el entrenamiento.

- **Aprendizaje No Supervisado.** A diferencia de la aproximación anterior, en el modelo de aprendizaje no supervisado, los datos de entrenamiento no están etiquetados. El objetivo aquí es que la neurona descubra patrones ocultos, estructuras o relaciones intrínsecas dentro de los datos sin ninguna guía externa sobre cuál debería ser la salida.

- **Aprendizaje Semi-Supervisado.** Este modelo de aprendizaje es una propuesta que se sitúa en un punto intermedio entre los dos anteriores. Utiliza una combinación de datos etiquetados y no etiquetados para entrenar el modelo. La idea es aprovechar la gran cantidad de datos no etiquetados para mejorar el rendimiento que se podría obtener utilizando solo una cantidad limitada de datos etiquetados.

- **Aprendizaje Auto-Supervisado.** En este modelo, el propio conjunto de datos no etiquetados se utiliza para generar las etiquetas o señales de supervisión. La neurona aprende a predecir una parte de los datos a partir de otra parte del mismo dato, creando tareas de aprendizaje supervisado artificialmente a partir de datos no etiquetados.

- **Aprendizaje por Refuerzo.** Este último modelo se basa en la interacción de un agente con el entorno sobre el que opera. El agente aprende a través de la recepción de recompensas o castigos por sus acciones. El objetivo es que el agente aprenda una política de comportamiento que maximice la recompensa acumulada a lo largo del tiempo.

Más allá de esta enumeración, es importante destacar que las dos grandes familias que engloban la mayoría de las estrategias de aprendizaje en estructuras neuronales son el aprendizaje supervisado y el no supervisado. Estas dos aproximaciones representan estrategias fundamentalmente diferentes en cuanto a la naturaleza de los datos de entrenamiento y los objetivos del aprendizaje. El resto de los modelos antes mencionados, como el aprendizaje semi-supervisado y el auto-supervisado, pueden considerarse, en este sentido, como variantes o extensiones de estas dos grandes categorías. Buscan, de alguna manera, mitigar las limitaciones o aprovechar las ventajas de cada una de ellas en contextos específicos.

A lo largo de la siguiente sección, profundizaremos en la descripción detallada de estas dos grandes aproximaciones y de sus variantes específicas y las pondremos en valor práctico en el marco de ejemplos realistas de aplicación, explorando sus características distintivas y sus desafíos inherentes.

## Modelos de Aprendizaje en Acción

Como hemos explicado en la sección anterior, en el ámbito de las Inteligencia Artificial Conexionista se reconocen distintos modelos de aprendizaje, cada uno con sus propias particularidades y aplicaciones. Sin embargo, un denominador común a todos ellos es la necesidad fundamental de contar con datos de entrenamiento suficientes en términos de volumen y que sean representativos del problema que se busca resolver.

Es crucial reiterar que todos los modelos de aprendizaje previamente mencionados se pueden agrupar en dos grandes categorías, las aproximaciones supervisadas y las no supervisadas. Esta dicotomía fundamental radica en la presencia o ausencia de etiquetas informativas asociadas a los datos de entrenamiento.

En los modelos supervisados, los datos de entrenamiento están meticulosamente etiquetados, proporcionando al sistema, durante el aprendizaje, la respuesta correcta para cada entrada. Esta precisión en la información permite aprender relaciones directas entre las entradas y las salidas deseadas. No obstante, la obtención de grandes volúmenes de datos etiquetados puede ser un proceso costoso, laborioso y, en muchos casos, inviable.

Por otro lado, en el aprendizaje no supervisado, resulta considerablemente más sencillo obtener grandes cantidades de datos, ya que estos no requieren el esfuerzo de ser etiquetados manualmente. Sin embargo, la ausencia de etiquetas implica que el modelo debe descubrir patrones y estructuras por sí mismo, lo que puede resultar en un aprendizaje más débil o menos directamente aplicable a tareas predictivas específicas.

Existen problemas que se adaptan de manera óptima a una estrategia de aprendizaje supervisado. Un ejemplo paradigmático es la clasificación de imágenes. Si disponemos de un conjunto de imágenes etiquetadas como gato o perro, podemos entrenar una red neuronal para que aprenda a distinguir entre ambas categorías y pueda clasificar correctamente nuevas imágenes no conocidas previamente. En este tipo de tareas, la información precisa de las etiquetas es crucial para guiar el aprendizaje del modelo hacia la solución deseada.

También existen escenarios donde solo es viable recurrir a estrategias de aprendizaje no supervisado. Un ejemplo ilustrativo es la segmentación de clientes en marketing. Si una empresa dispone de una gran cantidad de datos sobre el comportamiento de sus clientes, pero no tiene etiquetas predefinidas sobre los diferentes tipos de clientes, un algoritmo de aprendizaje no supervisado podría identificar grupos de clientes con patrones de comportamiento similares, revelando segmentos de mercado útiles para estrategias de marketing personalizadas.

Para mitigar las diferencias inherentes entre ambas aproximaciones y tratar de combinar sus ventajas, se han ideado en los últimos tiempos diversas variantes de modelos de aprendizaje. Estas pueden considerarse a caballo entre una estrategia supervisada y no supersivada y, según la perspectiva, también pueden en ocasiones considerarse como casos particulares de una de las dos categorías.

Así, En el aprendizaje semi-supervisado, se busca un equilibrio entre la disponibilidad de grandes cantidades de datos no etiquetados y la información valiosa proporcionada por un conjunto más pequeño de datos etiquetados. Por ejemplo, en el procesamiento del lenguaje natural, podría ser costoso etiquetar grandes corpus de texto para tareas como la clasificación de sentimientos. Sin embargo, se podría utilizar una pequeña porción de texto etiquetado junto con una gran cantidad de texto sin etiquetar para mejorar el rendimiento de un modelo de clasificación. La idea intuitiva es que un dato no etiquetado que presente similaridad con otros datos etiquetados adquiera, por mimetismo, la etiqueta de los datos de su vecindad.

En el aprendizaje auto-supervisado, por otro lado, la idea reside en generar las propias etiquetas a partir de los datos no etiquetados. Por ejemplo, en el entrenamiento de modelos de lenguaje, se puede ocultar una palabra dentro de una frase conocida y entrenar al modelo para que la prediga basándose en el contexto de las palabras circundantes. De esta manera, el propio texto sirve como fuente de supervisión, permitiendo entrenar modelos muy potentes con grandes cantidades de datos sin necesidad de un etiquetado manual.

Pero sin lugar a dudas, uno de los modelos de aprendizaje que está más de rabiosa actualidad en los últimos tiempos es el aprendizaje por refuerzo. En este modelo, el sistema aprende a través de la interacción directa con un entorno dinámico. Los datos de aprendizaje no son proporcionados explícitamente, sino que se extraen directamente de la observación de los cambios que provocan las acciones aplicadas por un agente operando sobre el entorno observado. El agente recibe recompensas o castigos en función de sus acciones, y el objetivo es aprender una política de comportamiento que maximice la recompensa acumulada a lo largo del tiempo. Un ejemplo paradigmático es el entrenamiento de agentes para jugar videojuegos, donde la recompensa podría ser la puntuación obtenida y el castigo la pérdida de una vida.

## Conclusiones

A lo largo de este artículo, hemos realizado un recorrido por los diferentes modelos de aprendizaje que sustentan la Inteligencia Artificial Conexionista. Hemos destacado cómo, dentro de este paradigma, la fase de aprendizaje se erige como una base diferencial y característica, permitiendo a los sistemas adquirir conocimiento y adaptarse a diversas tareas a partir de la experiencia.

Hemos revisado los cinco modelos de aprendizaje característicos dentro de este perímetro. Cada uno de ellos presenta sus propias particularidades en cuanto a la naturaleza de los datos de entrenamiento y los objetivos del aprendizaje. Pero desde un punto de vista estratégico, podemos dividirlos en dos grandes familias fundamentales. Por un lado destacan los modelos supervisados que se basan en datos etiquetados y, por otro, los modelos no supervisados que operan con datos no etiquetados. El resto de modelos que hemos discutido a lo largo de este artículo son soluciones de compromiso que persiguen equilibrar las ventajas y dificultades de ambas categorías de aprendizaje.

En terminos generales, la elección del modelo de aprendizaje adecuado dependerá en gran medida de la naturaleza del problema a resolver y de la disponibilidad de datos apropiados. Sin embargo, las aproximaciones no etiquetadas a veces constituyen una estrategia adecuada e incluso preferible. Son de particular interés cuando el objetivo principal es descubrir patrones ocultos o estructuras intrínsecas en los datos sin inducir criterios de comportamiento predefinidos. El análisis de clusters o la reducción de dimensionalidad son ejemplos de tareas donde el aprendizaje no supervisado puede ser especialmente valioso.

Contrariamente, los modelos supervisados demuestran una gran eficacia cuando se dispone de datos etiquetados de calidad y el objetivo es realizar predicciones o clasificaciones precisas. La capacidad de aprender directamente de ejemplos con respuestas conocidas los convierte en la opción predilecta para una amplia gama de aplicaciones en visión por computador, procesamiento del lenguaje natural y muchas otras áreas.

Con este artículo, damos por finalizada esta serie introductoria a la Inteligencia Artificial Conexionista, que ha comenzado explorando el concepto de la neurona artificial y presentando su interpretación geométrica práctica en el campo de la ingeniería, para culminar discutiendo los modelos fundamentales de operación y aprendizaje que permiten a las estructuras sistemicas basadas en neuronas artificiales adquirir la inteligencia que las caracteriza.