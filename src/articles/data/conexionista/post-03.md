---
title  : Modelos de Operación
slug   : modelos-de-operacion
author : Javier Vélez
date   : Abril 2024
---

## Introducción

Como ya hemos mencionado a lo largo de esta serie, los inicios de la Inteligencia Artificial Conexionista se remontan a los trabajos iniciales de Mc Cullock y Pitts al definir un modelo formal de neurona artificial capaz de ofrecer una representación simplificada de la intrincada estructura de las células nerviosas humanas. Pero su contribución fue más allá de esta mera descripción.

El modelo propuesto por estos autores ofrecía además un marco operativo. Una manera de entender el funcionamiento elemental del procesamiento neuronal. Esta perspectiva abría la puerta a la posibilidad de realizar razonamientos basados en los pilares de la lógica fundamental, uniendo así los dominios de la neurociencia teórica y la incipiente ciencia de la computación.

Sin embargo, la reinterpretación de la neurona que hizo Rosemblatt allá por 1948 como un clasificador geométrico supuso un cambio radical en la concepción de estas unidades computacionales. Este giro copernicano permitió visualizar la neurona no solo como un modelo lógico formal, sino como una entidad capaz de discernir patrones dentro de un espacio de datos reales.

Esta idea, estresaba la conveniencia de modular la configuración de los pesos sinápticos de las neuronas artificiales, para interpretarlos en términos de parámetros formales que determinan la influencia de cada señal de entrada sobre la señal de respuesta. En efecto, ajustando estos pesos de manera adecuada, se conseguía que la neurona aprendiera a realizar tareas específicas de clasificación. La clasificación se dibujaría, de esta forma, como la capacidad básica fundamental a partir de la cual era posible hacer emerger comportamiento inteligente de carácter más elaborado.

Pero más alla de eso, aún quedaba por descubrir si existian otros usos potenciales de estas estructuras artificiales. Si podrían los sistemas centrados en estructuras neuronales artificiales dar respuesta a otros problemas fundamentales de la inteligencia o basarse en otra suerte de operaciones atómicas diferenes a la clasificación. Para dar respuesta a esta pregunta, a lo largo de este artículo nos adentraremos en la exploración de los principales modelos de operación que se han desarrollado vinculados al uso de las estructuras neuronales de Mc Cullock y Pitts.

## Modelos de Operación

La neurona artificial surgió inicialmente como un modelo formal que buscaba emular, en un nivel abstracto, el comportamiento de las neuronas biológicas. Se ofrecía así una versión computable que no solo describía una visión estructural simplificada de las células nerviosas, sino también su comportamiento intrínseco de activación y transmisión de señales.

Pero si bien el modelo de Mc Cullock-Pitts sentó las bases teóricas de lo que años después se conocería como Inteligencia Artificial Conexionista, fue Frank Rosenblatt quien adelantó una interpretación pragmática del uso de las neuronas como agentes de clasificación paramétricos, entidades autonomamente entrenadas que mostraban la capacidad de separar linealmente diferentes categorías de datos mediante el ajuste de sus pesos sinápticos.

Sin embargo, aún quedaba por explorar si las neuronas artificiales exhibirían otras capacidades o usos pragmáticos más allá de la clasificación binaria. La exploración de esta cuestión reveló un abanico de posibles modelos de operaciona alternativos que han definido el panorama de la Inteligencia Artificial Conexionista hasta nuestros días. A continuación, describimos estos modelos:

- **Clasificación.** El objetivo de la clasificación es asignar un nuevo dato de entrada a una de dos categorías predefinidas. Este es el uso más directamente asociado a la neurona artificial de Mc Cullock y Pitts. Pero cuando se definen estructuras sistémicas de varias neuronas especializadas conformadas en red, es posible crear modelos de clasificación más complejos no lineales que sean además capaces de operar en espacios de clasificación no binarios.

- **Clusterización.** El objetivo de la clusterización es agrupar los datos presentes en el espacio en conjuntos por citerios de similaridad sin un conocimiento previo de las categorías existentes. Las estructuras neuronales pueden aprender representaciones de los datos que resaltan sus similitudes inherentes, permitiendo así la identifiación de grupos naturales. Este tipo de problemas es de gran utilidad práctica aunque aunque su uso es menos común dado que requiere de una lógica de activación por criterios de vecindad dentro de una estructra de neuroras organizadas de acuerdo a una disposición espacial.

- **Predicción.** El objetivo de los modelos de operación predictivos es estimar un valor futuro o valor de tendencia desconocido a partir de los datos históricos introducidos en el modelo durante la fase de entrenamiento. Las redes neuronales pueden aprender las relaciones complejas y las dependencias estructurales presentes en los datos para realizar pronósticos que resultan de utilidad de cara a realizar predicciones o inferencias de valores no conocidos. Disponer de una buena representatividad del espectro de datos durante la fase de entrenamiento resulta vital en este tipo de problemas.

- **Proyección.** A menudo, los conjuntos de datos contienen una gran cantidad de características, lo que puede dificultar su análisis y visualización. El objetivo de la proyección es, de esta manera, transformar los datos a un espacio de menor dimensionalidad, preservando la mayor cantidad posible de información relevante. Las redes neuronales pueden aprender representaciones más compactas de los datos, facilitando su comprensión y el desarrollo de modelos más eficientes. Los encoders y autoencoders, de gran vigencia en nuestros días, son una pragmática de uso de este modelo.

- **Generación.** El objetivo de este modelo es la creación de nuevos datos sintéticos o artificiales que compartan características similares con las del conjunto de datos de entrenamiento. Las redes neuronales generativas aprenden la distribución subyacente de los datos y pueden realizar muestreos sobre la misma para producir nuevos valores realistas. Los modelos de lenguaje extendidos, tan utilizados en la actualidad, usan, de manera intensiva, este modelo de operación. 

Es importante señalar que muchos de los modelos de operación que aquí resumimos encuentran su aplicación a través de arquitecturas de redes neuronales más complejas que los modelos básicos de neuronas individuales que hemos introducido hasta el momento. Redes neuronales profundas, redes convolucionales o redes recurrentes son ejemplos de estas estructuras más elaboradas.

La exploración detallada del funcionamiento interno y las aplicaciones específicas de estos modelos de redes neuronales más avanzados será el foco de otras series de artículos dedicadas a la Inteligencia Artificial Conexionista. Sin embargo, nuestro objetivo en estas líneas es ofrecer una visión panorámica de las formas canónicas en las que se puede operar con la Inteligencia Artificial Conexionista, sentando así una base sólida para futuras discusiones.

## Modelos de Operación en Acción

Si algo hemos aprendido del desarrollo y la aplicación de la Inteligencia Artificial Conexionista es su enfoque diferencial con respecto a otras ramas. Esta distinción radica en la manera en que se aborda la resolución de problemas y la consigue hacer emerger comportamiento inteligente.

En los modelos de inteligencia Heurística o Inteligencia de Enjambre, por ejemplo, la solución a un problema se construye a través de la definición explícita de reglas, estrategias o comportamientos individuales que, al interactuar, generan una inteligencia colectiva. El conocimiento se codifica de forma declarativa o mediante la definición de algoritmos específicos.

De manera similar, en los modelos de Inteligencia Simbólica, el razonamiento se basa en la manipulación de símbolos y reglas lógicas predefinidas. El conocimiento se representa explícitamente y la inferencia se realiza mediante la aplicación de reglas formales.

Sin embargo, en los modelos de Inteligencia Conexionista, la aproximación es notablemente distinta. En lugar de codificar explícitamente el conocimiento o las reglas de comportamiento, se adopta una estrategia basada en el aprendizaje a partir de los datos. Este paradigma se articula en los siguientes pasos fundamentales:

* Primero se crean complejas estructuras neuronales de carácter artificial y generalistas, diseñadas para ser flexibles y capaces de aprender una amplia gama de funciones. Estas arquitecturas pueden variar significativamente en su topología, número de capas y tipos de conexiones entre las neuronas.

* Después se somete a estas estructuras sistémicas a procesos de aprendizaje bien definidos, basados en la exposición exhaustiva y sistemática de grandes cantidades de datos realistas de entrenamiento. Durante este proceso, los pesos sinápticos de la red se ajustan iterativamente en función de los errores cometidos al procesar los datos.

* De esta forma se consigue, mediante este proceso de ajuste paramétrico, que el todo sistémico aprenda directamente del conocimiento latente en los datos de entrenamiento. La red neuronal internaliza los patrones, las regularidades y las dependencias presentes en los datos sin necesidad de una programación explícita de estas relaciones.

* Como resultado del aprendizaje, emerge un comportamiento miméticamente equivalente al adquirido durante la fase de entrenamiento. La red neuronal entrenada es capaz de generalizar su conocimiento a nuevos datos no vistos previamente, realizando tareas como clasificación, predicción o generación con un nivel de precisión significativo.

La ventaja fundamental de las aproximaciones dirigidas por los datos radica en su capacidad para aprender automáticamente representaciones complejas de los datos, sin requerir un conocimiento experto profundo sobre la estructura subyacente del problema. Esto contrasta con los enfoques simbólicos o heurísticos, donde la calidad de la solución depende en gran medida de la habilidad del diseñador para codificar el conocimiento relevante. Veamos ahora algunos ejemplos concretos de aplicación de los modelos de operación que hemos descrito a lo largo de este texto, ilustrando cómo las redes neuronales abordan cada uno de estos problemas:

- **Clasificación.** Consideremos el problema de clasificar imágenes de frutas en "manzana", "plátano" o "naranja". Una red neuronal neuronal podría entrenarse con miles de imágenes etiquetadas de cada fruta. La red aprendería a extraer características visuales relevantes como la forma, el color o la textura y a asociarlas con cada categoría, permitiendo así clasificar nuevas imágenes con alta precisión.

- **Clusterización.** Imaginemos un conjunto de datos de clientes de una tienda online, con información sobre sus compras y su comportamiento de navegación. Una red neuronal podría aprender una representación de baja dimensión de estos datos que capture las similitudes entre los clientes. Al analizar esta representación, se podrían identificar grupos de clientes con patrones de compra similares, lo que permitiría segmentar el mercado para campañas de marketing personalizadas.

- **Predicción.** Pensemos en la tarea de predecir la demanda de un determinado producto en función de factores como el precio, la temporada y las campañas publicitarias. Una red neuronal, especialmente diseñada con memoria a lo largo del tiempo, podría aprender las dependencias temporales en los datos de ventas históricos y otros factores relevantes para realizar pronósticos precisos de la demanda futura.

- **Proyección.** Consideremos un conjunto de datos genómicos con miles de variables para cada paciente. Una red neuronal con un cuello de botella de baja dimensión podría aprender una representación comprimida de la información genética, preservando las principales fuentes de variabilidad entre los pacientes. Esta representación de menor dimensión facilitaría la visualización de los datos y la identificación de subgrupos de pacientes con características genéticas similares.

- **Generación.** Imaginemos el objetivo de generar imágenes realistas de rostros humanos. Una red generativa podría entrenarse con un gran conjunto de datos de imágenes de rostros. El generador aprendería a crear nuevas imágenes que fueran indistinguibles de las imágenes reales del conjunto de datos.

Si algo se ha demostrado de manera consistente a lo largo del tiempo es que las arquitecturas inteligentes dirigidas por los datos son y han sido las más potentes y prometedoras en muchos dominios de aplicación. En primer lugar, estas aproximaciones reflejan de manera más auténtica la estructura inherente del problema, aprendiendo directamente de los datos en lugar de depender de modelos artificiales predefinidos que a menudo simplifican en exceso la realidad.

Ademas, pueden ser ajustadas y adaptadas dinámicamente para incorporar nuevos comportamientos y conocimientos ante la llegada de nueva evidencia en forma de datos de entrenamiento adicionales. Esta capacidad de aprendizaje continuo es una ventaja significativa en entornos dinámicos.

Por otro lado, no requieren del esfuerzo, a menudo considerable, de crear modelos artificiales complejos que pueden ser costosos de construir y cuya validez realista puede ser cuestionable. La inteligencia emerge directamente de los datos y dadas las condiciones de cómputo actuales, las soluciones de Inteligencia Artificial Conexionista han demostrado ser las más fiables y escalables hasta la fecha para una amplia gama de problemas complejos.

No obstante, este enfoque constructivo no ha estado exento de críticas. Una de las principales limitaciones convencionalmente señaladas radica en la necesidad de disponer de grandes volumenes de datos de entrenamiento de alta calidad para lograr un rendimiento óptimo. En efecto, la falta de datos suficientemente representativos suele llevar, frecuentemente, a modelos subóptimos o sesgados. Y lo cierto es que a veces, la obtención de datos, reales y convenientemente etiquetados, para toda suerte de problemas puede ser un desafío significativo, tanto en términos de coste como de disponibilidad. Pero este es un tema que abordaremos con mayor detalle en el siguiente artículo que da cierre esta serie.

## Conclusiones

A lo largo de este artículo, hemos presentado los diferentes modelos de operación fundamentales que se encuentran vinculados al campo de la Inteligencia Artificial Conexionista. Hemos explorado cómo las redes neuronales pueden ser empleadas para abordar problemas de clasificación, clusterización, predicción, proyección y generación de datos.

En esencia, estamos hablando de un paradigma de resolución de problemas que se basa en la creación de estructuras computacionales complejas, ingenuamente inspiradas en la arquitectura del cerebro biológico, y en el entrenamiento de las mismas a partir de grandes cantidades de datos.

Se trata, por tanto, de soluciones dirigidas fundamentalmente por los datos y basadas en procesos formales de aprendizaje automático. Y es que, la capacidad de estas redes para extraer patrones complejos y generalizar su conocimiento hacia nuevas estructuras de problema ha consolidado esta estrategia como una de las aproximaciones más viables y prometedoras en el campo de la Inteligencia Artificial.

La idea central de basar los comportamientos inteligentes a partir de procesos formales de aprendizaje dirigidos por los datos ha dado forma metodológica a todas las actividades dentro de la Inteligencia Artificial Conexionista hasta el punto que, hoy por hoy, la fase de entrenamiento es considerada como un elemento central en toda actividad de diseño y que diferencia esta aproximación de otras aproximaciones de la IA, como exploraremos con mayor detalle en otras series.

Si bien, desde un punto de vista formal, la aplicación de esta aproximación hoy en día no se puede refutar como una solución de éxito en muchos dominios, no ha estado exenta de críticas y desafíos a lo largo de su historia y en la actualidad. El proceso de diseño constructivo siempre va acompañado de retos significativos inherentes. Por un lado, conseguir conjuntos de datos de entrenamiento reales y representativos para toda suerte de problemas a veces no es una tarea sencilla y puede requerir una inversión significativa de tiempo y recursos. Por otro lado, las necesidades de cómputo para entrenar modelos de redes neuronales complejos han generado problemas de escalado en el pasado, si bien los avances en hardware y software están mitigando estas limitaciones de manera constante. En el próximo y último artículo de esta serie, abordaremos precisamente estas cuestiones al presentar los distintos modelos de aprendizaje que pueden aplicarse para entrenar redes neuronales.